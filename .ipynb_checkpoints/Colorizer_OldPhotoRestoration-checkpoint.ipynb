{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from skimage import io, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import TensorflowUtils as utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space for global  variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width and height of input images \n",
    "input_size = 128\n",
    "\n",
    "# directory for input images\n",
    "input_directory = 'Data/OldImages/'\n",
    "\n",
    "# directory for checkpoints (save / restore models)\n",
    "# download the l2 loss error model if necessary \n",
    "l2_checkpoints      = \"Models/CheckpointsL2/\"\n",
    "checkpoints_l2_link = \"https://www.dropbox.com/s/0nv5qm7f3h06avv/CheckpointsL2.zip?dl=1\"\n",
    "utils.maybe_download_and_extract(\"Models\", checkpoints_l2_link, is_zipfile=True)\n",
    "\n",
    "# download the huber loss error model if necessary \n",
    "huber_checkpoints      = \"Models/CheckpointsHuber/\"\n",
    "checkpoints_huber_link = \"https://www.dropbox.com/s/r1k1dol4wzwdaqe/CheckpointsHuber.zip?dl=1\"\n",
    "utils.maybe_download_and_extract(\"Models\", checkpoints_huber_link, is_zipfile=True)\n",
    "\n",
    "# download the pairwise mean squared error model if necessary \n",
    "pmse_checkpoints     = \"Models/CheckpointsPairwiseMSE\"\n",
    "checkpoints_mse_link = \"https://www.dropbox.com/s/xux39xsmgyo0y1r/CheckpointsPairwiseMSE.zip?dl=1\"\n",
    "utils.maybe_download_and_extract(\"Models\", checkpoints_mse_link, is_zipfile=True)\n",
    "\n",
    "# set checkpoints variable to the proper checkpoint\n",
    "checkpoints = pmse_checkpoints\n",
    "\n",
    "# where to find and store the pre-trained VGG model \n",
    "model_dir = \"Models/VGGModel/\"\n",
    "model_url = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the names of the images in that directory and shuffle the names\n",
    "input_images = np.asarray([x for x in os.listdir(input_directory) if x.endswith(\".jpg\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the AutoEncoder network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill-in-the-blanks for the VGG pre-trained network \n",
    "def vgg_net(weights, image):\n",
    "    layers = (\n",
    "        # 'conv1_1', 'relu1_1',\n",
    "        'conv1_2', 'relu1_2', 'pool1',\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "\n",
    "    net = {}\n",
    "    current = image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i + 2][0][0][0][0]\n",
    "            kernels = utils.get_variable(np.transpose(kernels, (1, 0, 2, 3)), name=name + \"_w\")\n",
    "            bias = utils.get_variable(bias.reshape(-1), name=name + \"_b\")\n",
    "            current = utils.conv2d_basic(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current, name=name)\n",
    "        elif kind == 'pool':\n",
    "            current = utils.avg_pool_2x2(current)\n",
    "        net[name] = current\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that builds the rest of the net\n",
    "def generator(images, train_phase):\n",
    "    \n",
    "    # Ge the model data and set up\n",
    "    print(\"setting up vgg initialized conv layers ...\")\n",
    "    model_data = utils.get_model_data(model_dir, model_url)\n",
    "    weights = np.squeeze(model_data['layers'])\n",
    "\n",
    "    # Build the remaining \"decoder\" that will colorize the image\n",
    "    with tf.variable_scope(\"generator\") as scope:\n",
    "        \n",
    "        # First Layer: 3x3 2dConv with bias follower by RELU\n",
    "        #              Need this layer because the input is only 1 channel\n",
    "        W0 = utils.weight_variable([3, 3, 1, 64], name=\"W0\")\n",
    "        b0 = utils.bias_variable([64], name=\"b0\")\n",
    "        conv0 = utils.conv2d_basic(images, W0, b0)\n",
    "        hrelu0 = tf.nn.relu(conv0, name=\"relu\")\n",
    "\n",
    "        # Add in the VGG network \n",
    "        image_net = vgg_net(weights, hrelu0)\n",
    "        vgg_final_layer = image_net[\"relu5_3\"]\n",
    "        pool5 = utils.max_pool_2x2(vgg_final_layer)\n",
    "        \n",
    "        # Decoder Level 1: begin to upscale the image and decrease the number of filters \n",
    "        #                  Use conv2d_transpose_strided() with 4x4 filter\n",
    "        deconv_shape1 = image_net[\"pool4\"].get_shape()\n",
    "        W_t1 = utils.weight_variable([4, 4, deconv_shape1[3].value, pool5.get_shape()[3].value], name=\"W_t1\")\n",
    "        b_t1 = utils.bias_variable([deconv_shape1[3].value], name=\"b_t1\")\n",
    "        conv_t1 = utils.conv2d_transpose_strided(pool5, W_t1, b_t1, output_shape=tf.shape(image_net[\"pool4\"]))\n",
    "        fuse_1 = tf.add(conv_t1, image_net[\"pool4\"], name=\"fuse_1\")\n",
    "\n",
    "        # Decoder Level 2: continue to upscale the image and decrease the number of filters \n",
    "        deconv_shape2 = image_net[\"pool3\"].get_shape()\n",
    "        print(deconv_shape2)\n",
    "        W_t2 = utils.weight_variable([4, 4, deconv_shape2[3].value, deconv_shape1[3].value], name=\"W_t2\")\n",
    "        b_t2 = utils.bias_variable([deconv_shape2[3].value], name=\"b_t2\")\n",
    "        conv_t2 = utils.conv2d_transpose_strided(fuse_1, W_t2, b_t2, output_shape=tf.shape(image_net[\"pool3\"]))\n",
    "        fuse_2 = tf.add(conv_t2, image_net[\"pool3\"], name=\"fuse_2\")\n",
    "        \n",
    "        # Decoder Level 3: continue to upscale the image and decrease the number of filters \n",
    "        shape = tf.shape(images)\n",
    "        deconv_shape3 = tf.stack([shape[0], shape[1], shape[2], 2])\n",
    "        W_t3 = utils.weight_variable([16, 16, 2, deconv_shape2[3].value], name=\"W_t3\")\n",
    "        b_t3 = utils.bias_variable([2], name=\"b_t3\")\n",
    "        pred = utils.conv2d_transpose_strided(fuse_2, W_t3, b_t3, output_shape=deconv_shape3, stride=8)\n",
    "\n",
    "    # return the concatenation of the input with the output to make it the full image\n",
    "    return tf.concat(axis=3, values=[images, pred], name=\"pred_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the network for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Setting up network...\")\n",
    "\n",
    "# Create placeholders for the input images and the output images \n",
    "train_phase = tf.placeholder(tf.bool, name=\"train_phase\")\n",
    "images = tf.placeholder(tf.float32, shape=[None, None, None, 1], name='L_image')\n",
    "lab_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"LAB_image\")\n",
    "\n",
    "# set pred_images to the output of the network \n",
    "pred_image = generator(images, train_phase)\n",
    "\n",
    "# define the loss function that we are minimizing as the L2-loss between the images \n",
    "gen_loss_pmse  = tf.reduce_mean(tf.losses.mean_pairwise_squared_error(lab_images, pred_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that takes the LAB layers and outputs the RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes the L, A, B, channels --> concatenates them, and converts them to RGB\n",
    "def labChannelsToRGB(l, a, b): \n",
    "    l[l > 99] = 99\n",
    "    new_lab = np.stack((l, a, b), axis=2)\n",
    "    new_lab = new_lab.astype('float64');\n",
    "    return color.lab2rgb(new_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to test an image and output the three relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes two images in the LAB-color-scheme and converts them to RGB before displaying them side-by-side\n",
    "def showNetPredictions(l_image, output_l2, output_huber, output_pmse, color_images): \n",
    "    num_tests = l_image.shape[0]\n",
    "    output_l2    = np.asarray(output_l2)[0,:,:,:,:]\n",
    "    output_huber = np.asarray(output_huber)[0,:,:,:,:]\n",
    "    output_pmse  = np.asarray(output_pmse)[0,:,:,:,:]\n",
    "\n",
    "    for i in range(num_tests): \n",
    "        fig=plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        \n",
    "        # Plot the Black-and-White Image \n",
    "        plt.subplot(1,5,1)\n",
    "        plt.title(\"Black and White Image\")\n",
    "        plt.imshow(l_image[i,:,:,0], cmap='gray')\n",
    "        \n",
    "        # Plot the Reconstructed / Predicted Image for L2 Loss\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.title(\"L2 Loss Predicted Image\")\n",
    "        plt.imshow(color.lab2rgb(output_l2[i,:,:,:].astype('float64')))\n",
    "        \n",
    "        # Plot the Reconstructed / Predicted Image for Huber Loss\n",
    "        plt.subplot(1,5,3)\n",
    "        plt.title(\"Huber Loss Predicted Image\")\n",
    "        plt.imshow(color.lab2rgb(output_huber[i,:,:,:].astype('float64')))\n",
    "        \n",
    "        # Plot the Reconstructed / Predicted Image for Huber Loss\n",
    "        plt.subplot(1,5,4)\n",
    "        plt.title(\"Pairwise MSE Loss Predicted Image\")\n",
    "        plt.imshow(color.lab2rgb(output_pmse[i,:,:,:].astype('float64')))\n",
    "        \n",
    "        # Plot the Original / Ground-Truth Image \n",
    "        plt.subplot(1,5,5)\n",
    "        plt.title(\"Ground Truth Image\")\n",
    "        plt.imshow(color.lab2rgb(color_images[i,:,:,:].astype('float64')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will get the saver \n",
    "saver = tf.train.Saver()\n",
    "should_resize = False\n",
    "input_size = 224\n",
    "\n",
    "# start a session\n",
    "with tf.Session() as sess:\n",
    "    # restore the pairwise MSE model\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoints)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else: \n",
    "        assert(False)  \n",
    "        \n",
    "    # iterate through the examples: \n",
    "    for i in range(len(input_images)): \n",
    "        im =  io.imread(input_directory+input_images[i])\n",
    "        if im.shape[2] != 3: \n",
    "            print(\"INCORRECT IMAGE CHANNELS\")\n",
    "            assert(0)\n",
    "        \n",
    "        # if we are resizing then do it\n",
    "        if should_resize:\n",
    "            im = resize(im, (input_size, input_size))\n",
    "        \n",
    "        # convert the image to LAB and extract the L channel\n",
    "        lab_img = color.rgb2lab(im)\n",
    "        lab_img = np.expand_dims(lab_img, axis=0)\n",
    "        lab_l = lab_img[:,:,:,0]\n",
    "        lab_l = np.expand_dims(lab_l, axis=3)\n",
    "        \n",
    "        # get the predicted image\n",
    "        feed_dict = {images: lab_l, lab_images: lab_img, train_phase: False}\n",
    "        output_pmse = sess.run([pred_image], feed_dict=feed_dict)\n",
    "        output_pmse = np.asarray(output_pmse)\n",
    "        output_pmse = output_pmse[0,0,:,:,:]\n",
    "        print(output_pmse.shape)\n",
    "        \n",
    "        # plot the l-channel image\n",
    "        fig=plt.figure(figsize=(14, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title(\"Black and White Image\")\n",
    "        plt.imshow(lab_l[0,:,:,0], cmap='gray')\n",
    "        \n",
    "        # plot the reconstructed / predicted image\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title(\"Pairwise MSE Loss Predicted Image\")\n",
    "        plt.imshow(color.lab2rgb(output_pmse.astype('float64')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
